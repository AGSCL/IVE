---
title: "Análisis de clases latentes"
date: "`r withr::with_locale(new = c('LC_TIME' = 'C'), code =format(Sys.time(),'%B %d, %Y'))`"
output:
  fidelius::html_password_protected:
    style:
      button_text: "Ingresar clave"
    password: "pablo"
    preview: false
    hint: "nombre revisor final de 2022"
    bundle: true
    output_format: 
      distill::distill_article:
        code_folding: true
        fig_height: 6
        fig_width: 8
        theme: flatly
        toc: yes
        toc_depth: 5
        toc_float: yes
---

```{css zoom-lib-src, echo = FALSE}
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
  
```

```{css hideOutput-lib-src, echo = FALSE}
<script src="hideOutput.js"></script> 
```

```{js hideOutput, echo = FALSE}
$(document).ready(function() {    
	$chunks = $('.fold');    
	$chunks.each(function () {      // add button to source code chunks     
	if ( $(this).hasClass('s') ) {       
		$('pre.r', this).prepend("<div class=\"showopt\">Show Source</div><br style=\"line-height:22px;\"/>");
       		$('pre.r', this).children('code').attr('class', 'folded');     
       		}      // add button to output chunks     
		if ( $(this).hasClass('o') ) {       
			$('pre:not(.r)', this).has('code').prepend("<div class=\"showopt\">Show Output</div><br style=\"line-height:22px;\"/>");       
			$('pre:not(.r)', this).children('code:not(r)').addClass('folded');        // add button to plots       
			$(this).find('img').wrap('<pre class=\"plot\"></pre>');       
			$('pre.plot', this).prepend("<div class=\"showopt\">Show Plot</div><br style=\"line-height:22px;\"/>");       
			$('pre.plot', this).children('img').addClass('folded');      
			}   
});    // hide all chunks when document is loaded   
	$('.folded').css('display', 'none')    // function to toggle the visibility   
	$('.showopt').click(function() {     
			var label = $(this).html();     
			if (label.indexOf("Show") >= 0) {       
				$(this).html(label.replace("Show", "Hide"));     
			} else {
			  $(this).html(label.replace("Hide", "Show"));     
			}     
	$(this).siblings('code, img').slideToggle('fast', 'swing');   
	}); 
}); 

```

```{=html}
<style type="text/css">
.showopt {   
  background-color: #004c93;   color: #FFFFFF;    width: 100px;   height: 20px;   text-align: center;   vertical-align: middle !important;   float: right;   font-family: sans-serif;   border-radius: 8px; 
  }

.showopt:hover {     
        background-color: #dfe4f2;
        color: #004c93; 
        }  
pre.plot {   
        background-color: white !important; 
        } 
.tablelines table, .tablelines td, .tablelines th {
        border: 1px solid black;
        }

.centrado {
    text-align: center;
}

.table.center {
    margin-left:auto; 
    margin-right:auto;
  }

/* https://vivekjaiskumar.medium.com/css-is-and-not-selector-17c942ec83f :is()*/

/* Applies to outputs that are not code other than R*/

pre {
  overflow-x: auto !important;
}
pre code {
  word-wrap: normal !important;
  white-space: pre !important;
}
/*
pre:not(.sourceCode) { 
  white-space: nowrap !important;
}
*/
.sourceCode { /* Important gives precedence  */
  font-size: 10px !important;
  line-height: 50% !important;
}

body{ /* Normal  */
      text-align: justify;
  }

.superbigimage{
    overflow-y:scroll;
    height:350px;
    white-space: nowrap;
    overflow-x: auto; 
    width:100%;
}
.superbigimage img{
    overflow-y: scroll;
    overflow-x: hidden;
}

.message { color:#446C6E; font-family: monospace;font-size: 10px; line-height: 110%; font-weight: bold;}
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 5px; text-align: justify;}
div.red { background-color:#e6bab1; border-radius: 5px; padding: 5px; text-align: justify;}

.pandoc-table { /* Should add !important; but it seems no necessary  */
  margin-left:auto; /* To center */
  margin-right:auto;
  border-collapse: collapse;
  table-layout: auto;
  font-size: 11px;
  overflow-y: auto;
  max-height:450px !important;
  white-space: nowrap;
  overflow-x: auto; 
  width:450px;
}

.pandoc-table th {/* header */
text-align: center !important;
font-size: 10px;
padding: 0px;
}

.pandoc-table td {
text-align: left !important;
font-size: 9px;
padding: 0px;
}

.pandoc-table caption {
    text-align: left !important;
    font-size: 11px !important;
}

.controlly{
    overflow-y:scroll;
    height:350px;
    overflow-x: scroll; 
}

</style>
```
```{=html}
<!-- We gotta do each function to hide code and outputs per section, by every ID, we gotta create a different function -->
<script>
function myFunction1() {
    var x = document.getElementById("myDIV");
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

<script>
function myFunction2() {
    var x = document.getElementById("myDIV2");
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>
```

```{r prev-setup, include = FALSE, cache=T, error=T}
rm(list=ls());gc()
load("OUT/data3.Rdata")


if(isTRUE(getOption('knitr.in.progress'))==T){
    clus_iter=250
    n_thread <- parallel::detectCores()-1
    nrep <- clus_iter # number of different initial values (could be n_thread too)
    n_class_max <- 10 # maximum number of classes to investigate
    n_bootstrap <- 200 # number of bootstrap samples
} else {
  input <- readline('¿Are you gonna run the dataset with the whole iterations? (Si/No): ')
  if(input=="Si"){
    clus_iter=500
    n_thread <- parallel::detectCores()-1
    nrep <- clus_iter # number of different initial values (could be n_thread too)
    n_class_max <- 10 # maximum number of classes to investigate
    n_bootstrap <- 200 # number of bootstrap samples
  } else {
    clus_iter=3
    n_thread <- parallel::detectCores()-2
    nrep <- clus_iter # number of different initial values (could be n_thread too)
    n_class_max <- 10 # maximum number of classes to investigate
    n_bootstrap <- 3 # number of bootstrap samples
  }
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# 1. leer data -------------------------------------------------------------

load("OUT/data3.Rdata")

if(!require(poLCAParallel)){devtools::install_github("QMUL/poLCAParallel@package")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(tableone)){install.packages("tableone")}
if(!require(compareGroups)){install.packages("compareGroups")}
if(!require(brms)){install.packages("brms")}
if(!require(parallel)){install.packages("parallel")}
if(!require(jtools)){install.packages("jtools")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(missRanger)){install.packages("missRanger")}
if(!require(ggstance)){install.packages("ggstance")}
if(!require(broom.mixed)){install.packages("broom.mixed")}
if(!require(polycor)){install.packages("polycor")}
if(!require(corrplot)){install.packages("corrplot")}
if(!require(leaps)){install.packages("leaps")}
#try(if(!require(sjPlot)){install.packages("sjPlot", dependencies = TRUE)}) #error parametersError: object 'standard_error_robust' is not exported by 'namespace:parameters'
if(!require(logistf)){install.packages("logistf")}
if(!require(finalfit)){install.packages("finalfit")}
if(!require(dlookr)){install.packages("dlookr")}
if(!require(emmeans)){install.packages("emmeans")}
if(!require(safeBinaryRegression)){install.packages("safeBinaryRegression")}
if(!require(bayestestR)){install.packages("bayestestR")}
if(!require(rstanarm)){install.packages("rstanarm")}
if(!require(here)){install.packages("here")}
if(!require(doParallel)){install.packages("doParallel")}
if(!require(poLCA)){install.packages("poLCA")}
if(!require(missForest)){install.packages("missForest")}
if(!require(githubinstall)){install.packages("githubinstall")}
if(!require(job)){install.packages("job")}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
lca_dir<-here::here()

copiar_nombres <- function(x,row.names=FALSE,col.names=TRUE,dec=",",...) {
  if(class(ungroup(x))[1]=="tbl_df"){
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)    
        }
  } else {
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)       
  }
 }
}  
guardar_tablas <- function (x,y) {writexl::write_xlsx(as.data.frame(x, keeprownames= T),paste0(y,".xlsx"))}
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#' Bivariate residuals for latent class models
#' 
#' Calculate the "bivariate residuals" (BVRs) between pairs of variables 
#' in a latent class model.
#' 
#' This function compares the model-implied (expected) counts in the crosstables
#' of all pairs of observed dependent variables to the observed counts. For each
#' pair, it calculates a "chi-square" statistic,
#' 
#' \deqn{\text{BVR} = \sum_{j, j'} \frac{(n_{jj'} - e_{jj'})^2}{e_{jj'}}},
#' 
#' where \eqn{n_{jj'}} are the observed counts for categories \eqn{j} and \eqn{j'} 
#' of the variables being crosstabulated, and \eqn{e_{jj'}} are
#' the expected counts under the latent class model. 
#' 
#' Note that the BVR does not follow an asymptotic chi-square distribution and
#' for accurate p-values, parametric bootstrapping is necessary (Oberski et al. 2013).
#' 
#' @param fit A poLCA fit object
#' @param tol Optional: tolerance for small expected counts
#' @param rescale_to_df Optional: whether to divide the pairwise "chi-square" values by 
#' the degrees of freedom of the local crosstable. Default is TRUE.
#' @return The table of bivariate residuals
#' @author Daniel Oberski (daniel.oberski@gmail.com)
#' @seealso \code{\link{poLCA}} for fitting the latent class model.
#' @references 
#' Oberski, DL, Van Kollenburg, GH and Vermunt, JK (2013). 
#'   A Monte Carlo evaluation of three methods to detect local dependence in binary data latent class models. 
#'   Advances in Data Analysis and Classification 7 (3), 267-279.
#' @examples
#' data(values)
#' f <- cbind(A, B, C, D) ~ 1
#' M0 <- poLCA(f,values, nclass=1, verbose = FALSE) 
#' bvr(M0) # 12.4, 5.7, 8.3, 15.6, ... 
bvr <- function(fit, tol = 1e-3, rescale_to_df = TRUE) {
  stopifnot(class(fit) == "poLCA")

  ov_names <- names(fit$predcell)[1:(ncol(fit$predcell) - 2)]
  ov_combn <- combn(ov_names, 2)

  get_bvr <- function(ov_pair) {
    form_obs <- as.formula(paste0("observed ~ ", ov_pair[1], " + ", ov_pair[2]))
    form_exp <- as.formula(paste0("expected ~ ", ov_pair[1], " + ", ov_pair[2]))

    counts_obs <- xtabs(form_obs, data = fit$predcell)
    counts_exp <- xtabs(form_exp, data = fit$predcell)
    counts_exp <- ifelse(counts_exp < tol, tol, counts_exp) # Prevent Inf/NaN

    bvr_df <- prod(dim(counts_exp) - 1)
    bvr_value <- sum((counts_obs - counts_exp)^2 / counts_exp)

    if(rescale_to_df) bvr_value <- bvr_value / bvr_df

    attr(bvr_value, "df") <- bvr_df

    bvr_value
  }

  bvr_pairs <- apply(ov_combn, 2, get_bvr)

  attr(bvr_pairs, "rescale_to_df") <- rescale_to_df
  attr(bvr_pairs, "class") <- "dist"
  attr(bvr_pairs, "Size") <- length(ov_names)
  attr(bvr_pairs, "Labels") <- ov_names
  attr(bvr_pairs, "Diag") <- FALSE
  attr(bvr_pairs, "Upper") <- FALSE

  bvr_pairs
}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
poLCA.entropy.fix <- function (lc)
{
  K.j <- sapply(lc$probs, ncol)
  fullcell <- expand.grid(sapply(K.j, seq, from = 1))
  P.c <- poLCA.predcell(lc, fullcell)
  return(-sum(P.c * log(P.c), na.rm = TRUE))
}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#Calculate entropy R2 for poLCA model

# MIT license
# Author: Daniel Oberski
# Input: result of a poLCA model fit
# Output: entropy R^2 statistic (Vermunt & Magidson, 2013, p. 71)
# See: daob.nl/wp-content/uploads/2015/07/ESRA-course-slides.pdf
# And: https://www.statisticalinnovations.com/wp-content/uploads/LGtecnical.pdf
machine_tolerance <- sqrt(.Machine$double.eps)
entropy.R2 <- function(fit) {
  entropy <- function(p) {
    p <- p[p > machine_tolerance] # since Lim_{p->0} p log(p) = 0
    sum(-p * log(p))
  }
  error_prior <- entropy(fit$P) # Class proportions
  error_post <- mean(apply(fit$posterior, 1, entropy))
  R2_entropy <- (error_prior - error_post) / error_prior
  R2_entropy
}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#http://researchdata.gla.ac.uk/879/1/Survey_data_processed_using_R.pdf
##Function to plot variable probabilites by latent class

## Function to undertake chisquare analayis and plot graphs of residuals and contributions
chisquaretest.predictions.function <-
 function(indfactor.data,
 predclass.data,
 noclasses,
 pitem,
 gitem,
 chirows,
 chicols) {
 chisquare.results <- chisq.test(indfactor.data, predclass.data)
 residuals.data <- chisquare.results$residuals
 colnames(residuals.data) <- chicols
 rownames(residuals.data) <- chirows
 title.text <-
 paste(
 "Residuals: chi Square Crosstabulation of\n",
 pitem,
 "and",
 gitem,
 "\n(Chisquare =",
 round(chisquare.results$statistic, 3),
 " p <",
 round(chisquare.results$p.value, 3),
 ")",
 sep = " "
 )
 corrplot(
 residuals.data,
 is.cor = FALSE,
 title = title.text,
 mar = c(0, 0, 4, 0)
 )
 contrib.data <-
 100 * residuals.data ^ 2 / chisquare.results$statistic
 round(contrib.data, 3)
 colnames(contrib.data) <- chicols
 rownames(contrib.data) <- chirows
 title.text <-
 title.text <-
 paste(
 "Contributions: chi Square Crosstabulation of\n",
 pitem,
 "and",
 gitem,
 "\n(Chisquare =",
 round(chisquare.results$statistic, 3),
 " p <",
 round(chisquare.results$p.value, 3),
 ")",
 sep = " "
 )
 corrplot(
 contrib.data,
 is.cor = FALSE,
 title = title.text,
 mar = c(0, 0, 4, 0)
 )
 return(chisquare.results)
 }
##Funciton for Cramers V test
cv.test = function(x, y) {
 CV = sqrt(chisq.test(x, y, correct = FALSE)$statistic /
 (length(x) * (min(
 length(unique(x)), length(unique(y))
 ) - 1)))
 print.noquote("Cramér V / Phi:")
 return(as.numeric(CV))
}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- ifelse(difftime(Sys.time(), now)>(60^2),difftime(Sys.time(), now)/(60^2),difftime(Sys.time(), now)/(60^1))
      # return a character string to show the time
      x<-ifelse(difftime(Sys.time(), now)>(60^2),paste("Time for this code chunk to run:", round(res,1), "hours"),paste("Time for this code chunk to run:", round(res,1), "minutes"))
      paste('<div class="message">', gsub('##', '\n', x),'</div>', sep = '\n')
    }
  }
}))
knitr::opts_chunk$set(time_it = TRUE)
```

<!---
#Ejemplo de aplicación y ejemplo
#https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fanalysisfunction.civilservice.gov.uk%2Fwp-content%2Fuploads%2F2017%2F02%2FA-Short-Guide-to-using-Latent-Class-Analysis-Final2.docx&wdOrigin=BROWSELINK
#Otro ejemplo: https://github.com/cran/poLCA/blob/master/inst/doc/poLCA-manual-example.R
#https://link.springer.com/article/10.1007/s00355-021-01365-4#additional-information
# Identifying these people can be challenging. We take various measures of subjective wellbeing (SWB) as indicators of the how well people are doing in life and employ Latent Class Analysis to identify those with greatest propensity to be among the worst-off in a nationally representative sample of over 215,000 people in the United Kingdom. Our results have important implications for how best to analyse data on SWB and who to target when looking to improve the lives of those with the lowest SW

#Identificar
#https://rpubs.com/eogawac/poLCA

#H:\Mi unidad\DOCUMENTOS\6.TESIS 2018\LCA NAQ\LCA Análisis de Clases Latentes (entregado).docx
--->


# Explore data

## Export

```{r explore-export-0, echo=FALSE}
data_cons_dt2<-
  dplyr::mutate(data_cons, 
                prev_tramo2=relevel(factor(prev_tramo2), ref = "ISAPRE"),
                anio=factor(anio))%>% dplyr::mutate(edad_mujer=cut(edad_mujer,4),
                                                    tpm4=cut(tpm,4),
                                                    tpm6=cut(tpm,6)) %>% 
  data.table::data.table()
```

```{r explore-export-1}
data_cons_dt2_pred_imp<-data_cons_dt2[,c("decision_rec", "anio",  "nacionalidad_rec", "region_rec", "prev_tramo2", "causal",  "niv_entrada_rec", "acps", "edad_mujer", "tpm" )] %>% 
  janitor::clean_names() %>% 
  dplyr::mutate(causal=factor(causal)) %>%
  dplyr::mutate(nacionalidad_rec=factor(nacionalidad_rec)) %>%
  dplyr::mutate(acps=factor(acps)) %>%
  dplyr::mutate(niv_entrada_rec=factor(niv_entrada_rec)) %>% 
  dplyr::mutate(region_rec=factor(region_rec)) %>% 
  data.frame()

registerDoParallel(cores=parallel::detectCores()-2)
doRNG::registerDoRNG(seed = 2125)

data_cons_dt2_pred_imp_imp1 <- missForest::missForest(data_cons_dt2_pred_imp, maxiter=1e2, ntree= 1e4, parallelize='forests', verbose = T)

library(rio)
rio::export(data_cons_dt2, "./_lca/lca0.dta")
rio::export(data_cons_dt2_pred_imp_imp1$ximp, "./_lca/lca0_imp.dta")
```


```{r comunas}
Comunas_PNDR <- readxl::read_excel("./_lca/Clasificacion-comunas-PNDR.xlsx")%>% 
  dplyr::mutate(cod= dplyr::case_when(as.character(cod_com)=="16101"~"8401",
                                      as.character(cod_com)=="16102"~"8402",
                                      as.character(cod_com)=="16103"~"8406",
                                      as.character(cod_com)=="16104"~"8407",
                                      as.character(cod_com)=="16105"~"8410",
                                      as.character(cod_com)=="16106"~"8411",
                                      as.character(cod_com)=="16107"~"8413",
                                      as.character(cod_com)=="16108"~"8418",
                                      as.character(cod_com)=="16109"~"8421",
                                      as.character(cod_com)=="16201"~"8414",
                                      as.character(cod_com)=="16202"~"8403",
                                      as.character(cod_com)=="16203"~"8404",
                                      as.character(cod_com)=="16204"~"8408",
                                      as.character(cod_com)=="16205"~"8412",
                                      as.character(cod_com)=="16206"~"8415",
                                      as.character(cod_com)=="16207"~"8420",
                                      as.character(cod_com)=="16301"~"8416",
                                      as.character(cod_com)=="16302"~"8405",
                                      as.character(cod_com)=="16303"~"8409",
                                      as.character(cod_com)=="16304"~"8417",
                                      as.character(cod_com)=="16305"~"8419",
                                      T~ as.character(cod_com)
                                      ))

data_cons_dt2<-
data_cons_dt2 %>% 
  dplyr::mutate(comuna_residencia_cod_rec= as.character(readr::parse_number(cod_comuna))) %>% #glimpse()
  dplyr::left_join(Comunas_PNDR[,c("cod", "Clasificación")], by= c("comuna_residencia_cod_rec"="cod")) %>% 
  dplyr::select(-comuna_residencia_cod_rec) %>% 
  dplyr::mutate(clas=factor(`Clasificación`))
```

# LCA

## Specify first model (unadjusted)

```{r paso2-definir-variables,eval=T, echo=T, paged.print=TRUE, eval=T}
preds <- c("decision_rec", "anio",  "nacionalidad_rec", "region_rec", "prev_tramo2", "causal", "niv_entrada_rec", "acps", "edad_mujer", "tpm4", "clas")
mydata_preds <- data_cons_dt2 %>% dplyr::mutate(across(preds, ~ dplyr::case_when(is.na(.)~ dplyr::n_distinct(.)+1, T~ as.numeric(factor(.))))) 
f_preds<-cbind(decision_rec, anio, nacionalidad_rec, region_rec, prev_tramo2, niv_entrada_rec, acps, edad_mujer, tpm4, clas)~1
f_adj <- cbind(decision_rec, anio, nacionalidad_rec, region_rec, prev_tramo2, niv_entrada_rec, acps, edad_mujer, tpm4, clas)~causal

f_df<-with(mydata_preds, cbind(decision_rec, anio, nacionalidad_rec, region_rec, prev_tramo2, niv_entrada_rec, acps, edad_mujer, tpm4, clas)~1)
#qdapTools::mtabulate(mydata_preds)
```
Following Lin and Dayton (1997), three criteria were applied to select the best model as follows.

- (a) The model should be identifiable.

- (b) The likelihood ratio v2 p-value for the model should be greater than 0.01, indicating that the model fits the data reasonably well.

- (c) The Bayesian information criterion BIC defined as L2 ) log(N) degrees of freedom should be the smallest among all competing models.

::: controlly
```{r paso2a-lca_select,eval=T, echo=T, paged.print=TRUE, eval=T, error=T}
#Biemer, P. P., & Wiesen, C. (2002). Measurement error evaluation of self-reported drug use: a latent class analysis of the US National Household Survey on Drug Abuse. Journal of the Royal Statistical Society: Series A (Statistics in Society), 165(1), 97–119. doi:10.1111/1467-985x.00612 

#<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%">
# f is the selected variables
# dat is the data
# nb_var is the number of selected variables
# k is the number of latent class generated
# nbr_repet is the number of repetition to
# reach the convergence of EM algorithm
# x es el código para las variables de los modelos
#seed es el numero random para las semillas. ej: 4345.
#Modo de calcular el mejor modelo.

#2023-01-20
#https://github.com/QMUL/poLCAParallel/blob/master/exec/3_blrt.R


old <- Sys.time()

set.seed(2125)
model_array <- list()
for (nclass in 1:n_class_max) {
  set.seed(2125)
  model <- poLCAParallel::poLCA(
    f_preds, 
    mydata_preds,
    nclass = nclass, 
    nrep = nrep, 
    n.thread = parallel::detectCores()-1,
    verbose = FALSE
  )
  model_array[[nclass]] <- model
 
    #progressbar
  cat(paste0(round(nclass / n_class_max * 100), '% completed'))
  Sys.sleep(.05)
  if (nclass == n_class_max) cat(': Done')
  else cat('\014')
}
model_array_ppio<-model_array

invisible("")
# store p values for each nclass, 1 to n_class_max
# store 0 for 1 number of class, ie this says you cannot have zero number of
# classes
p_value_array <- c(0)
# for all number of classes investigated:
#   - store the log likelihood ratio
#   - store all bootstrap samples log likelihoods ratios
fitted_log_ratio_array <- rep(NaN, n_class_max)
bootstrap_log_ratio_array <- list()

# do the bootstrap likelihood ratio test for each number of classes
for (nclass in 2:n_class_max) {

  # get the null and alt models
  # these are models with one number of class differences
  null_model <- model_array[[nclass - 1]]
  alt_model <- model_array[[nclass]]

  # for each bootstrap sample, store the log likelihood ratio here
  bootstrap_results <- poLCAParallel::blrt(
    null_model, alt_model,
    n_bootstrap, n_thread, nrep
  )

  # log likelihood ratio to compare the two models
  fitted_log_ratio_array[nclass] <- bootstrap_results[["fitted_log_ratio"]]
  # store the log likelihoods ratios for all bootstrap samples
  bootstrap_log_ratio_array[[nclass]] <-
    bootstrap_results[["bootstrap_log_ratio"]]
  # store the p value for this nclass
  p_value_array <- c(p_value_array, bootstrap_results[["p_value"]])
  
  #progress bar
  cat(paste0(round(nclass / n_class_max * 100), '% completed'))
  Sys.sleep(.05)
  if (nclass == n_class_max) cat(': Done')
  else cat('\014')
}

new<-(Sys.time())
time_diff <- (Sys.time() - old)/60
paste0("The model took ",round(new-old,2)," hours")

model_array_ppio2 <- model_array
fitted_log_ratio_array_ppio <- fitted_log_ratio_array
bootstrap_log_ratio_array_ppio <- bootstrap_log_ratio_array
bootstrap_results_ppio <- bootstrap_results
p_value_array_ppio <- p_value_array

#Within poLCA, parameter estimates are obtained by a procedure that repeatedly improves estimates.
#This is stopped when no further improvements are obtained, or until a maximum number of iterations is reached. The starting values are the values at which such repetitions were started. Increasing the number 4 R. ACHTERHOF ET AL.of iterations (cycles within each estimation) and setting more different starting values for each repetition results in a greater likelihood that the global (rather than local) maximum of the log-likelihood function (and thus, the best possible solution) is reached. The maximum number of iterations was chosen as 10.000, and 500 different sets of starting values were used (thus going beyond the recommendations by Linzer & Lewis, 2011; Oberski, 2016). As such, the influence of chance was minimized while the reproducibility of the results was maximized.
```
:::


::: controlly
```{r table-ppio,eval=T, echo=T, paged.print=TRUE, eval=T, error=T}

tab_ppio<-data.frame(matrix(rep(999,18),nrow=1)) #number of columns
names(tab_ppio)<-c("log-likelihood","Chi2","Chi2_pval",
                     "resid. df","AIC", "BIC",
                     "aBIC","cAIC","likelihood-ratio","LLik_pval","Entropy", "Entropy.R2","Dev Change","df","pval", "n_classes","blrt","blrt_pval")
relative.entropy<-function(lc){
  en<--sum(lc$posterior*
             log(lc$posterior),na.rm=T)
  e<-1-en/(nrow(lc$posterior)*log(ncol(lc$posterior)))
  return(e)
}

for(i in 2:10){
  skip_to_next <- FALSE
  
  # Note that print(b) fails since b doesn't exist
tryCatch(head(matrix(model_array_ppio[[i]]$predclass),0), error = function(e) { skip_to_next <<- TRUE})
  if(skip_to_next) { next }   else {
    
    mod<- model_array_ppio[[i]]
    mod_min1<- model_array_ppio[[i-1]]
    
    mod$y <- mod$y
    mod$K.j <- t(matrix(apply(mod$y,2,max)))
    mod$C <- max(mod$K.j)
    mod$J <- ncol(mod$y)
    mod$I <- mod$J # number of items            
    mod$df <- mod$C^mod$I - mod$npar - 1      
    mod$Chisq.pvalue <-(1 - pchisq(mod$Chisq, mod$df))
    mod$Gsq.pvalue <-(1 - pchisq(mod$Gsq, mod$df))
    tab_ppio<- rbind(tab_ppio,
                       c(mod$llik,
                         mod$Chisq,
                         mod$Chisq.pvalue,
                         mod$resid.df,
                         mod$aic,
                         mod$bic,
                         (-2*mod$llik) +
                           (log((mod$N + 2)/24) *
                              mod$npar),
                         (-2*mod$llik) +
                           mod$npar *
                           (1 + log(mod$N)),
                         mod$Gsq,
                         mod$Gsq.pvalue,
                         relative.entropy(mod),
                         entropy.R2(mod),
                         (mod_min1$Gsq- mod$Gsq),
                         (mod_min1$resid.df- mod$resid.df),
                         (pchisq(mod_min1$Gsq- mod$Gsq,  mod_min1$resid.df- mod$resid.df)),
                         i,
                         fitted_log_ratio_array_ppio[[i]],
                         p_value_array_ppio[[i]]
                         ))
  }
}
tab_ppio<-round(tab_ppio[-1,],2)

tab_ppio %>% knitr::kable("markdown", caption="Comparison of unadjusted models")
```
:::

```{r fig1-Comparison, echo=T, fig.align='center', fig.pos='H', fig.cap= "Figure 1. Comparative of models of latent classes (2 to 10, from left to right)", message=FALSE, error=T, eval=T, fig.height=10}

manualcolors<-c('indianred1','cornflowerblue', 'gray50', 'darkolivegreen4', 'slateblue2', 
                'firebrick4', 'goldenrod4')
#"#FF0000" "#00A08A" "#F2AD00" "#F98400" "#5BBCD6"
#"#798E87" "#C27D38" "#CCC591" "#29211F"
                  
#ppio_newList$lc_entropy_table%>%
tab_ppio %>% 
  #dplyr::mutate_at(.vars=vars(Gsq, Llik, AIC, mAIC, AICc, HT, cAIC, AICu, BIC, aBIC, HQ), .funs = funs(`zw`=scale(.)))%>%
  tidyr::pivot_longer(cols = -n_classes,names_to="indices", values_to="value",values_drop_na = F)%>%
  #dplyr::group_by(Nclass)%>%
  dplyr::mutate(indices=factor(indices, levels=c('log-likelihood', 'Chi2', 'Chi2_pval', 'resid. df', "AIC", 'BIC', 'aBIC', 'cAIC', 'likelihood-ratio', "LLik_pval","Dev Change","df","pval","Entropy","Entropy.R2","blrt","blrt_pval","n_classes"),labels=c("Log-Likelihood",'Chi2','p value','Degrees of Freedom (resid)','Akaike Information\nCriterion (AIC)',"Bayesian Information\nCriterion (BIC)","Adjusted BIC","Corrected AIC","Deviance",'p value Dev',"Deviance Change\n(with previous model)","df","pval of diffs","Entropy","Entropy R2","Bootstrap Likelihood\nRatio Test","P value Bootstrap\nLikelihood value test","Number of Classes"))) %>% 
  #dplyr::filter(indices %in% c('Akaike Information\nCriterion (AIC)',"Bayesian Information\nCriterion (BIC)", "Number of Classes")) %>%
  dplyr::filter(grepl("AIC|BIC",indices))%>%
  dplyr::mutate(n_classes=factor(n_classes)) %>% 
  ggplot(aes(x=n_classes,y=value,color=indices, group=indices))+
  geom_line()+
  geom_point()+
  theme_classic()+
  labs(x="Number of Classes", y="Value")+
  labs(color = "Indices")+
  geom_vline(xintercept=which.min(tab_ppio$BIC))+
  labs(caption="Vertical line= Selected model")+
  theme_classic(base_size=15)
#,'Gsq_zw', 'Llik_zw', 'AIC_zw', 'mAIC_zw', 'AICc_zw', 'HT_zw', 'cAIC_zw', 'AICu_zw', 'BIC_zw', 'aBIC_zw', 'HQ_zw'

#lca_selectnaq %>% dplyr::arrange(BIC) "Adjusted BIC",

#International Journal of Workplace Health Management  (Zhang et al., 2018).
```

<br>

## Specify second model (adjusted)

::: controlly
```{r paso3b-lca-select,eval=T, echo=T, paged.print=TRUE, eval=T, error=T}
#Biemer, P. P., & Wiesen, C. (2002). Measurement error evaluation of self-reported drug use: a latent class analysis of the US National Household Survey on Drug Abuse. Journal of the Royal Statistical Society: Series A (Statistics in Society), 165(1), 97–119. doi:10.1111/1467-985x.00612 

#<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:400px; overflow-x: scroll; width:100%">
# f is the selected variables
# dat is the data
# nb_var is the number of selected variables
# k is the number of latent class generated
# nbr_repet is the number of repetition to
# reach the convergence of EM algorithm
# x es el código para las variables de los modelos
#seed es el numero random para las semillas. ej: 4345.
#Modo de calcular el mejor modelo.

#2023-01-20
#https://github.com/QMUL/poLCAParallel/blob/master/exec/3_blrt.R


old2 <- Sys.time()

set.seed(2125)
model_array <- list()
for (nclass in 1:n_class_max) {
  set.seed(2125)
  model <- poLCAParallel::poLCA(
    f_preds, 
    mydata_preds,
    nclass = nclass, 
    nrep = nrep, 
    n.thread = parallel::detectCores()-1,
    verbose = FALSE
  )
  model_array[[nclass]] <- model
 
    #progressbar
  cat(paste0(round(nclass / n_class_max * 100), '% completed'))
  Sys.sleep(.05)
  if (nclass == n_class_max) cat(': Done')
  else cat('\014')
}
model_array_adj<-model_array

invisible("")
# store p values for each nclass, 1 to n_class_max
# store 0 for 1 number of class, ie this says you cannot have zero number of
# classes
p_value_array <- c(0)
# for all number of classes investigated:
#   - store the log likelihood ratio
#   - store all bootstrap samples log likelihoods ratios
fitted_log_ratio_array <- rep(NaN, n_class_max)
bootstrap_log_ratio_array <- list()

# do the bootstrap likelihood ratio test for each number of classes
for (nclass in 2:n_class_max) {

  # get the null and alt models
  # these are models with one number of class differences
  null_model <- model_array[[nclass - 1]]
  alt_model <- model_array[[nclass]]

  # for each bootstrap sample, store the log likelihood ratio here
  bootstrap_results <- poLCAParallel::blrt(
    null_model, alt_model,
    n_bootstrap, n_thread, nrep
  )

  # log likelihood ratio to compare the two models
  fitted_log_ratio_array[nclass] <- bootstrap_results[["fitted_log_ratio"]]
  # store the log likelihoods ratios for all bootstrap samples
  bootstrap_log_ratio_array[[nclass]] <-
    bootstrap_results[["bootstrap_log_ratio"]]
  # store the p value for this nclass
  p_value_array <- c(p_value_array, bootstrap_results[["p_value"]])
  
  #progress bar
  cat(paste0(round(nclass / n_class_max * 100), '% completed'))
  Sys.sleep(.05)
  if (nclass == n_class_max) cat(': Done')
  else cat('\014')
}

new2<-(Sys.time())
paste0("The model took ",round(new2-old2,2)," hours")

model_array_adj2 <- model_array
fitted_log_ratio_array_adj <- fitted_log_ratio_array
bootstrap_log_ratio_array_adj <- bootstrap_log_ratio_array
bootstrap_results_adj <- bootstrap_results
p_value_array_adj <- p_value_array

#Within poLCA, parameter estimates are obtained by a procedure that repeatedly improves estimates.
#This is stopped when no further improvements are obtained, or until a maximum number of iterations is reached. The starting values are the values at which such repetitions were started. Increasing the number 4 R. ACHTERHOF ET AL.of iterations (cycles within each estimation) and setting more different starting values for each repetition results in a greater likelihood that the global (rather than local) maximum of the log-likelihood function (and thus, the best possible solution) is reached. The maximum number of iterations was chosen as 10.000, and 500 different sets of starting values were used (thus going beyond the recommendations by Linzer & Lewis, 2011; Oberski, 2016). As such, the influence of chance was minimized while the reproducibility of the results was maximized.
```
:::


::: controlly
```{r table-adj,eval=T, echo=T, paged.print=TRUE, eval=T, error=T}

tab_adj<-data.frame(matrix(rep(999,18),nrow=1)) #number of columns
names(tab_adj)<-c("log-likelihood","Chi2","Chi2_pval",
                     "resid. df","AIC", "BIC",
                     "aBIC","cAIC","likelihood-ratio","LLik_pval","Entropy", "Entropy.R2","Dev Change","df","pval", "n_classes","blrt","blrt_pval")

for(i in 2:10){
  skip_to_next <- FALSE
  
  # Note that print(b) fails since b doesn't exist
tryCatch(head(matrix(model_array_adj[[i]]$predclass),0), error = function(e) { skip_to_next <<- TRUE})
  if(skip_to_next) { next }   else {
    
    mod<- model_array_adj[[i]]
    mod_min1<- model_array_adj[[i-1]]
    
    mod$y <- mod$y
    mod$K.j <- t(matrix(apply(mod$y,2,max)))
    mod$C <- max(mod$K.j)
    mod$J <- ncol(mod$y)
    mod$I <- mod$J # number of items            
    mod$df <- mod$C^mod$I - mod$npar - 1      
    mod$Chisq.pvalue <-(1 - pchisq(mod$Chisq, mod$df))
    mod$Gsq.pvalue <-(1 - pchisq(mod$Gsq, mod$df))
    tab_adj<- rbind(tab_adj,
                       c(mod$llik,
                         mod$Chisq,
                         mod$Chisq.pvalue,
                         mod$resid.df,
                         mod$aic,
                         mod$bic,
                         (-2*mod$llik) +
                           (log((mod$N + 2)/24) *
                              mod$npar),
                         (-2*mod$llik) +
                           mod$npar *
                           (1 + log(mod$N)),
                         mod$Gsq,
                         mod$Gsq.pvalue,
                         relative.entropy(mod),
                         entropy.R2(mod),
                         (mod_min1$Gsq- mod$Gsq),
                         (mod_min1$resid.df- mod$resid.df),
                         (pchisq(mod_min1$Gsq- mod$Gsq,  mod_min1$resid.df- mod$resid.df)),
                         i,
                         fitted_log_ratio_array_adj[[i]],
                         p_value_array_adj[[i]]
                         ))
  }
}
tab_adj<-round(tab_adj[-1,],2)

tab_adj %>% knitr::kable("markdown", caption="Comparison of adjusted models")
```
:::

```{r fig2-Comparison, echo=T, fig.align='center', fig.pos='H', fig.cap= "Figure 2. Comparative of models of latent classes (2 to 10, from left to right)", message=FALSE, error=T, eval=T, fig.height=10}

manualcolors<-c('indianred1','cornflowerblue', 'gray50', 'darkolivegreen4', 'slateblue2', 
                'firebrick4', 'goldenrod4')
#"#FF0000" "#00A08A" "#F2AD00" "#F98400" "#5BBCD6"
#"#798E87" "#C27D38" "#CCC591" "#29211F"
                  
#ppio_newList$lc_entropy_table%>%
tab_adj %>% 
  #dplyr::mutate_at(.vars=vars(Gsq, Llik, AIC, mAIC, AICc, HT, cAIC, AICu, BIC, aBIC, HQ), .funs = funs(`zw`=scale(.)))%>%
  tidyr::pivot_longer(cols = -n_classes,names_to="indices", values_to="value",values_drop_na = F)%>%
  #dplyr::group_by(Nclass)%>%
  dplyr::mutate(indices=factor(indices, levels=c('log-likelihood', 'Chi2', 'Chi2_pval', 'resid. df', "AIC", 'BIC', 'aBIC', 'cAIC', 'likelihood-ratio', "LLik_pval","Dev Change","df","pval","Entropy","Entropy.R2","blrt","blrt_pval","n_classes"),labels=c("Log-Likelihood",'Chi2','p value','Degrees of Freedom (resid)','Akaike Information\nCriterion (AIC)',"Bayesian Information\nCriterion (BIC)","Adjusted BIC","Corrected AIC","Deviance",'p value Dev',"Deviance Change\n(with previous model)","df","pval of diffs","Entropy","Entropy R2","Bootstrap Likelihood\nRatio Test","P value Bootstrap\nLikelihood value test","Number of Classes"))) %>% 
  #dplyr::filter(indices %in% c('Akaike Information\nCriterion (AIC)',"Bayesian Information\nCriterion (BIC)", "Number of Classes")) %>%
  dplyr::filter(grepl("AIC|BIC",indices))%>%
  dplyr::mutate(n_classes=factor(n_classes)) %>% 
  ggplot(aes(x=n_classes,y=value,color=indices, group=indices))+
  geom_line()+
  geom_point()+
  theme_classic()+
  labs(x="Number of Classes", y="Value")+
  labs(color = "Indices")+
  geom_vline(xintercept=which.min(tab_adj$BIC))+
  labs(caption="Vertical line= Selected model")+
  theme_classic(base_size=15)
#,'Gsq_zw', 'Llik_zw', 'AIC_zw', 'mAIC_zw', 'AICc_zw', 'HT_zw', 'cAIC_zw', 'AICu_zw', 'BIC_zw', 'aBIC_zw', 'HQ_zw'

#lca_selectnaq %>% dplyr::arrange(BIC) "Adjusted BIC",

#International Journal of Workplace Health Management  (Zhang et al., 2018).
```

<br>

# Session Info

```{r session-info, echo=T, error=T, message=TRUE, paged.print=TRUE}
message(Sys.getenv("R_LIBS_USER"))
Sys.Date()
message(paste0("Editor context: ", rstudioapi::getSourceEditorContext()$path))

save.image(paste0(dirname(rstudioapi::getSourceEditorContext()$path),"/","lca.RData"))

sesion_info <- devtools::session_info()
dplyr::select(
  tibble::as_tibble(sesion_info$packages),
  c(package, loadedversion, source)
) %>% 
  DT::datatable(filter = 'top', colnames = c('Row number' =1,'Variable' = 2, 'Percentage'= 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        '', htmltools::em('Packages')),
      options=list(
initComplete = htmlwidgets::JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({
            'font-family': 'Helvetica Neue',
            'font-size': '50%', 
            'code-inline-font-size': '15%', 
            'white-space': 'nowrap',
            'line-height': '0.75em',
            'min-height': '0.5em'
            });",#;
        "}")))
```
